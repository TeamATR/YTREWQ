{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考サイト\n",
    "http://keik-117.hatenablog.com/entry/2016/07/01/185011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio #https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudioからダウンロードしてインストール(ネット経由のpipはうまくいかない)\n",
    "               #＋VS2017 CrossTTool cmdでpip実行（C++コンパイラcl.exeが必要なため）\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.stats import kurtosis\n",
    "from IPython.display import display, Audio\n",
    "from scipy import signal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 録音用の関数を定義\n",
    "def recording():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP1\n",
    "２つの独立音源 s1 ,  s2 を用意する。  \n",
    "録音するか、または録音済みの音声ファイルを読み込んで、２つの独立音源 s1 ,  s2 の標本配列を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##record and write\n",
    "# s1 = np.fromstring(b''.join(recording()), np.int16)\n",
    "# wav.write('data/kurodasan_high.wav', RATE, s1)\n",
    "\n",
    "# read second sample\n",
    "# s1_temp = wav.read('sato_sony.wav')[1]\n",
    "s1 = wav.read('data/kurodasan.wav')[1]\n",
    "# s1 = s1_temp[2000:20000,0].reshape(-1)\n",
    "# s1 = wav.read('dl1.wav')[1]\n",
    "\n",
    "plt.xlim(len(s1))\n",
    "plt.title('time series of first sample')\n",
    "plt.plot(s1)\n",
    "\n",
    "display(Audio(s1, rate=RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##record and write\n",
    "# s2 = np.fromstring(b''.join(recording()), np.int16)\n",
    "# wav.write('data/kurodasan_high.wav', RATE, s2)\n",
    "\n",
    "# read second sample\n",
    "# s2_temp = wav.read('sato_sony.wav')[1]\n",
    "s2 = wav.read('data/shimamurasan.wav')[1]\n",
    "# s2 = s2_temp[2000:20000,0].reshape(-1)\n",
    "# s2 = wav.read('dl2.wav')[1]\n",
    "\n",
    "plt.xlim(len(s1))\n",
    "plt.title('time series of first sample')\n",
    "plt.plot(s1)\n",
    "\n",
    "display(Audio(s1, rate=RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP2\n",
    "s1 ,  s2 の音量をランダムな強さ  R によって加法合成した２つの合成音源 x1 ,  x2 を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly mix\n",
    "R = np.random.rand(4).reshape(2, 2)\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "print('合成する各音源の音量倍率 R:\\n{}'.format(R))\n",
    "\n",
    "x1, x2 = np.dot(R, (s1, s2))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(len(x1))\n",
    "plt.title('time series of x1, randomly mixed (s1: {0:.2f}, s2: {1:.2f})'.format(R[0,0], R[0,1]))\n",
    "plt.plot(x1)\n",
    "\n",
    "display(Audio(x1, rate=RATE))\n",
    "\n",
    "plt.figure()\n",
    "plt.title('time series of x2. randomly mixed (s1: {0:.2f}, s2: {1:.2f})'.format(R[1,0], R[1,1]))\n",
    "plt.xlim(len(x2))\n",
    "plt.plot(x2)\n",
    "\n",
    "display(Audio(x2, rate=RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x1, x2, s=1, marker='x', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP3\n",
    "ICA の手法に基づいて x1 ,  x2 から独立音源 s1 ,  s2 を推定して音源を分離し、分離音源 s1^ ,  s2^ を得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音量レベル　[-1, 1] の区間における尖度 kurtosis 分布を計算する\n",
    "def kurtosis_of_mixture(p, x1, x2):\n",
    "    sample1 = x1[::10]\n",
    "    sample2 = x2[::10]\n",
    "    p2 = np.sqrt(1 - p ** 2)\n",
    "    mixed_series = p * sample1 + p2 * sample2\n",
    "    m2 = np.std(mixed_series) ** 2\n",
    "    m4 = np.mean([x ** 4 for x in mixed_series])\n",
    "    return m4 / (m2 ** 2) - 3  # fix to Fisher's definition with -3\n",
    "\n",
    "p_array = np.arange(-1,1,0.01)\n",
    "k_array = [kurtosis_of_mixture(item, x1, x2) for item in p_array]\n",
    "\n",
    "plt.plot(p_array, k_array)\n",
    "plt.title('kurtosis of remixed x1 and x2')\n",
    "plt.xlabel('power of x1')\n",
    "plt.ylabel('kurtosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciPy 版\n",
    "# [-1, 1] の区間における尖度 kurtosis を計算する\n",
    "def kurtosis_of_mixture(p, x1, x2):\n",
    "    sample1 = x1[::10]\n",
    "    sample2 = x2[::10]\n",
    "    p2 = np.sqrt(1 - p ** 2)\n",
    "    mixed_series = p * sample1 + p2 * sample2\n",
    "    return kurtosis(mixed_series)\n",
    "\n",
    "p_array = np.arange(-1,1,0.01)\n",
    "k_array = [kurtosis_of_mixture(item, x1, x2) for item in p_array]\n",
    "\n",
    "plt.plot(p_array, k_array)\n",
    "plt.title('kurtosis of remixed x1 and x2')\n",
    "plt.xlabel('power of x1')\n",
    "plt.ylabel('kurtosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尖度の最大・最小値を用いて、合成音源 x1, x2 の独立性が最大となるように行列変換する\n",
    "k_max = max(k_array)\n",
    "k_argmax = p_array[k_array.index(k_max)]\n",
    "k_min = min(k_array)\n",
    "k_argmin = p_array[k_array.index(k_min)]\n",
    "\n",
    "print('''max(k): {:.2f}, argmax(k): {:.2f},\n",
    "min(k): {:.2f}, argmin(k): {:.2f}'''.format(\n",
    "        k_max, k_argmax,\n",
    "        k_min, k_argmin))\n",
    "\n",
    "c = np.array((\n",
    "            (k_argmax, np.sqrt(1 - k_argmax ** 2)), \n",
    "            (k_argmin, np.sqrt(1 - k_argmin ** 2))\n",
    "        ))\n",
    "\n",
    "sep1, sep2 = np.dot(c, np.array((x1, x2)))\n",
    "\n",
    "print('分離音源 sep1')\n",
    "display(Audio(sep1, rate=RATE))\n",
    "print('分離音源 sep2')\n",
    "display(Audio(sep2, rate=RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分離音源 s1^ ,  s2^ の散布図を描いてみる。  \n",
    "x1 ,  x2 の散布図のように、明らかな相関のある散布図に比べ、 s1 ,  s2 の散布図のような上下左右対称に近い散布図に近づいていることが想定される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('scatter of separated sources')\n",
    "plt.scatter(sep1, sep2, s=1, marker='x', alpha=0.2)\n",
    "plt.xlabel('sep1')\n",
    "plt.ylabel('sep2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  STEP4 ここからが本題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得られた音声データを周波数領域に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_Func(data,StartCellNum,CalLength,WindowNum):\n",
    "    #FFTをかけるデータの設定\n",
    "    Caldata = data[StartCellNum:StartCellNum + CalLength]\n",
    "    #窓関数の選択：WindowNum →0: ハニング窓,1:ハミング窓,Others:ブラックマン窓 \n",
    "    if WindowNum == 0:\n",
    "        w = signal.hann(CalLength)\n",
    "    elif WindowNum == 1:\n",
    "        w = signal.hamming(CalLength)\n",
    "    else:\n",
    "        w = signal.blackman(CalLength)\n",
    "    ##FFT計算\n",
    "    FFTReturn =np.fft.fft(w*Caldata)\n",
    "    \n",
    "    return FFTReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iFFT_Func(data,StartCellNum,CalLength,WindowNum):\n",
    "    #FFTをかけるデータの設定\n",
    "    Caldata = data[StartCellNum:StartCellNum + CalLength]\n",
    "    #窓関数の選択：WindowNum →0: ハニング窓,1:ハミング窓,Others:ブラックマン窓 \n",
    "    if WindowNum == 0:\n",
    "        w = signal.hann(CalLength)\n",
    "    elif WindowNum == 1:\n",
    "        w = signal.hamming(CalLength)\n",
    "    else:\n",
    "        w = signal.blackman(CalLength)\n",
    "    ##iFFT計算\n",
    "    iFFTReturn =np.fft.ifft(w*Caldata)\n",
    "    \n",
    "    return iFFTReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解析するデータの設定\n",
    "data = s2\n",
    "#チューニングパラメータの設定\n",
    "StartCellNum = 30000\n",
    "CalLength = 20000\n",
    "WindowNum = 0\n",
    "##FFTの実行\n",
    "FFTData = FFT_Func(data,StartCellNum,CalLength,WindowNum)\n",
    "#絶対値(FFTAmp)に変換\n",
    "FFTAmp = np.abs(FFTData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFTをかけたデータの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#周波数間隔計算のための値設定\n",
    "N = CalLength         # サンプル数\n",
    "dt = 1/48000          # サンプリング間隔\n",
    "voice_lim_low = 20    # 人の声周波数最小値\n",
    "voice_lim_high = 1000 # 人の声周波数最大値\n",
    "#X軸の設定（人の発声可能周波数まで）\n",
    "voice_freq = np.linspace(0,voice_lim_high,int((voice_lim_high)/(1/dt)*N)) # 周波数\n",
    "#直流成分を0にする(5は設計パラメータ：適宜変更)\n",
    "FFTAmp[:5] = 0\n",
    "plt.plot(voice_freq,FFTAmp[:int(voice_lim_high/(1/dt)*N)], label='|F(k)|')\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "leg = plt.legend(loc=1, fontsize=25)\n",
    "leg.get_frame().set_alpha(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  STEP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ケプストラム空間でLPF処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ケプストラム変換のためのデータ設定\n",
    "CalLengthKps,col  = np.shape(FFTData.reshape(-1,1))\n",
    "StartCellNumKps = 0\n",
    "WindowNumKps = 0\n",
    "# ケプストラム変換（FFTしたデータにFFTをかける）\n",
    "KpsData = FFT_Func(FFTData,StartCellNumKps,CalLengthKps,WindowNumKps)\n",
    "KpsAmp = np.abs(KpsData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ケプストラム変換したデータをフィルタリングしたデータを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#フィルタリング設計パラメータ\n",
    "FltNum = 5000\n",
    "#LPFの実施:FltNum以降の高周波成分をcut\n",
    "FltKpsData = np.copy(KpsData)\n",
    "FltKpsData[FltNum:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フィルタリングの結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 18\n",
    "fig = plt.figure(figsize=(16,4.5))\n",
    "font = {'family':'Yu Mincho'}\n",
    "matplotlib.rc('font', **font) \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.abs(KpsData),label = 'Raw Data',color = 'r')\n",
    "plt.xlabel('DataNum(Time)', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "# plt.ylim([1300,1600])\n",
    "# plt.xlim([-1,7])\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.abs(FltKpsData),label = 'Filtering Data',color = 'b')\n",
    "plt.xlabel('DataNum(Time)', fontsize=20)\n",
    "# plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ifftをかけて周波数領域に再変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ケプストラムを周波数領域に再変換（FFTをFFTしたデータにiFFTをかける）\n",
    "FltFFTData = iFFT_Func(FltKpsData,StartCellNumKps,CalLengthKps,WindowNumKps)\n",
    "FltFFTAmp = np.abs(FltFFTData)\n",
    "# plt.plot(voice_freq,ifft_Kps[:int(voice_lim_high/(1/dt)*N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フィルタリング結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4.5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(voice_freq,FFTAmp[:int(voice_lim_high/(1/dt)*N)], label='Raw|F(k)|')\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(voice_freq,FltFFTAmp[:int(voice_lim_high/(1/dt)*N)], label='Flt|F(k)|')\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  STEP6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己相関を用いて基本振動数を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoCorrelation(ACData,DataLength):\n",
    "    ac_data = ACData[:DataLength]-np.mean(ACData[:DataLength])\n",
    "    corr = np.correlate(ac_data, ac_data, \"full\")\n",
    "    return corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_peak(data):#ピークを算出：左右の点より大きい点を抽出\n",
    "\tpeaks_val = []\n",
    "\tpeaks_index = []\n",
    "\tfor i in range(2, data.size):\n",
    "\t\tif data[i-1] - data[i-2] >= 0 and data[i] - data[i-1] < 0:\n",
    "\t\t\tpeaks_val.append(data[i-1])\n",
    "\t\t\tpeaks_index.append(i-1)\n",
    "\tmax_index = peaks_val.index(max(peaks_val))\n",
    "\treturn peaks_index[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己相関の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己相関パラメータ設定\n",
    "DataLength = int(voice_lim_high/(1/dt)*N)#人の声最大周波数まで\n",
    "\n",
    "#自己相関を計算\n",
    "# 1:ケプストラム変換考慮ver\n",
    "ACDataFlt = FltFFTAmp\n",
    "CorrFlt = AutoCorrelation(ACDataFlt,DataLength)\n",
    "# 2:ケプストラム変換考慮しないver\n",
    "ACData = FFTAmp\n",
    "Corr = AutoCorrelation(ACData,DataLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(Corr, label='AutoCorrelation')\n",
    "# plt.xlabel('Dif',fontsize=20)\n",
    "# plt.ylabel('Amplitude', fontsize=20)\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "fig = plt.figure(figsize=(16,4.5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(CorrFlt, label='AutoCorrelationKps')\n",
    "plt.xlabel('Dif',fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Corr, label='AutoCorrelationRaw')\n",
    "plt.xlabel('Dif',fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本振動数の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#２番目のピークを算出※1番目のピークはずれ（基本振動数）＝０\n",
    "ScndPeakFlt = pick_peak(CorrFlt[(DataLength - 1):])\n",
    "ScndPeak = pick_peak(Corr[(DataLength - 1):])\n",
    "#周波数成分に変換\n",
    "FundFreqFlt = ScndPeakFlt * (1/dt)/N\n",
    "FundFreq = ScndPeak * (1/dt)/N\n",
    "print(\"基本振動数Ksp =\",FundFreqFlt,\"Hz\")\n",
    "print(\"基本振動数 =\",FundFreq,\"Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#振動数確認用（上のプロットを再度描画）\n",
    "fig = plt.figure(figsize=(16,4.5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(voice_freq,FFTAmp[:int(voice_lim_high/(1/dt)*N)], label='Raw|F(k)|')\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(voice_freq,FltFFTAmp[:int(voice_lim_high/(1/dt)*N)], label='Flt|F(k)|')\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
