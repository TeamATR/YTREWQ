{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'ocrd-fork-pylsd == 0.0.3'\n",
    "import time\n",
    "from pylsd.lsd import lsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "def display_cv_image(image, format='.png'):\n",
    "    decoded_bytes = cv2.imencode(format, image)[1].tobytes()\n",
    "    display(Image(data=decoded_bytes))\n",
    "    \n",
    "def time_file_name(fname):\n",
    "    return time.strftime(\"%d_%b_%Y_\", time.gmtime()) + fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime(\"%d_%b_%Y\", time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像読込\n",
    "img1 = cv2.imread(\"./res/ATRMoji00.png\")\n",
    "img2 = cv2.imread(\"./res/ATRMoji01.png\")\n",
    "\n",
    "# A-KAZE検出器の生成\n",
    "detector = cv2.AKAZE_create()\n",
    "\n",
    "# 特徴量の検出と特徴量ベクトルの計算\n",
    "kp1, des1 = detector.detectAndCompute(img1, None)\n",
    "kp2, des2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "# Brute-Force Matcherの生成\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# 特徴量ベクトル同士をBrute-Force＆KNNでマッチング\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# データを間引く\n",
    "ratio = 0.2\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio * n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "# 特徴量をマッチング状況に応じてソート\n",
    "good = sorted(matches, key = lambda x : x[1].distance)\n",
    "\n",
    "# 対応する特徴点同士を描画\n",
    "img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good[:2], None, flags=2)\n",
    "\n",
    "display_cv_image(img3, '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像読込\n",
    "img1 = cv2.imread(\"./res/ATRMoji00.png\")\n",
    "img2 = cv2.imread(\"./res/ATRMoji01.png\")\n",
    "\n",
    "# A-KAZE検出器の生成\n",
    "detector = cv2.AKAZE_create()\n",
    "\n",
    "# 特徴量の検出と特徴量ベクトルの計算\n",
    "kp1, des1 = detector.detectAndCompute(img1, None)\n",
    "kp2, des2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "# Brute-Force Matcherの生成\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# 特徴量ベクトル同士をBrute-Force＆KNNでマッチング\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# データを間引く\n",
    "ratio = 0.2\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio * n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "# 特徴量をマッチング状況に応じてソート\n",
    "good = sorted(matches, key = lambda x : x[1].distance)\n",
    "\n",
    "# 対応する特徴点同士を描画\n",
    "img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good[:2], None, flags=2)\n",
    "\n",
    "display_cv_image(img3, '.png')\n",
    "\n",
    "# 特徴量データを取得\n",
    "\n",
    "q_kp = []\n",
    "t_kp = []\n",
    "\n",
    "\n",
    "\n",
    "for p in good[:2]:\n",
    "    for px in p:\n",
    "        q_kp.append(kp1[px.queryIdx])\n",
    "        t_kp.append(kp2[px.trainIdx])\n",
    "\n",
    "# 加工対象の画像から特徴点間の角度と距離を計算\n",
    "q_x1, q_y1 = q_kp[0]\n",
    "q_x2, q_y2 = q_kp[-1]\n",
    "\n",
    "q_deg = math.atan2(q_y2 - q_y1, q_x2 - q_x1) * 180 / math.pi\n",
    "q_len = math.sqrt((q_x2 - q_x1) ** 2 + (q_y2 - q_y1) ** 2)\n",
    "\n",
    "# テンプレート画像から特徴点間の角度と距離を計算\n",
    "t_x1, t_y1 = t_kp[0]\n",
    "t_x2, t_y2 = t_kp[-1]\n",
    "\n",
    "t_deg = math.atan2(t_y2 - t_y1, t_x2 - t_x1) * 180 / math.pi\n",
    "t_len = math.sqrt((t_x2 - t_x1) ** 2 + (t_y2 - t_y1) ** 2)\n",
    "\n",
    "# 切出し位置の計算\n",
    "x1 = q_x1 - t_x1 * (q_len / t_len)\n",
    "x2 = x1 + img2.shape[1] * (q_len / t_len)\n",
    "\n",
    "y1 = q_y1 - t_y1 * (q_len / t_len)\n",
    "y2 = y1 + img2.shape[0] * (q_len / t_len)\n",
    "\n",
    "# 画像サイズ\n",
    "x, y, c = img1.shape\n",
    "size = (x, y)\n",
    "\n",
    "# 回転の中心位置\n",
    "center = (q_x1, q_y1)\n",
    "\n",
    "# 回転角度\n",
    "angle = q_deg - t_deg\n",
    "\n",
    "# サイズ比率\n",
    "scale = 1.0\n",
    "\n",
    "# 回転変換行列の算出\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "# アフィン変換\n",
    "img_rot = cv2.warpAffine(img1, rotation_matrix, size, flags=cv2.INTER_CUBIC)\n",
    "\n",
    "# 画像の切出し\n",
    "img_rot = img_rot[y1:y2, x1:x2]\n",
    "\n",
    "# 縮尺調整\n",
    "x, y, c = img2.shape\n",
    "img_rot = cv2.resize(img_rot, (y, x))\n",
    "\n",
    "# 結果表示\n",
    "display_cv_image(img_rot, '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kokokara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import cv2\n",
    "#画像をグレースケールで読み込む\n",
    "imgcol = cv2.imread(\"./res/ATRMoji00.png\",1)\n",
    "img = cv2.imread(\"./res/ATRMoji00.png\",0)\n",
    "temp = cv2.imread(\"./res/ATRMoji01.png\", 0)\n",
    "#マッチングテンプレートを実行\n",
    "#比較方法はcv2.TM_CCOEFF_NORMEDを選択\n",
    "result = cv2.matchTemplate(img, temp, cv2.TM_CCOEFF_NORMED)\n",
    "#検出結果から検出領域の位置を取得\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "top_left = max_loc\n",
    "w, h = temp.shape[::-1]\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "#検出領域を四角で囲んで保存\n",
    "result = cv2.imread(\"./res/ATRMoji00.png\")\n",
    "cv2.rectangle(result,top_left, bottom_right, (255, 0, 0), 2)\n",
    "display_cv_image(result, '.png')\n",
    "cv2.imwrite(\"./res/result.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgH = cv2.imread(\"./res/ATRMoji00.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(imgH, cv2.COLOR_BGR2GRAY)\n",
    "display_cv_image(gray, '.png')\n",
    "#cv2.imwrite(\"./res/ATRMoji00G.png\", gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray2 = cv2.bitwise_not(gray)\n",
    "display_cv_image(gray2, '.png')\n",
    "#cv2.imwrite(\"./res/ATRMoji00HAN.png\", gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kokomade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(gray2, rho=1, theta=np.pi/360, threshold=80, minLineLength=250, maxLineGap=5)\n",
    "print(lines)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    # 赤線を引く\n",
    "    red_line_img = cv2.line(imgcol, (x1,y1), (x2,y2), (0,200,255), 3)\n",
    "    cv2.imwrite(\"./res/ATRMoji00HAFU2999.png\", red_line_img)\n",
    "display_cv_image(red_line_img, '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img00 = imgcol.copy()\n",
    "#img00 = cv2.resize(img00,(int(img00.shape[1]/5),int(img00.shape[0]/5)))\n",
    "gray = cv2.cvtColor(img00,cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray,(5,5),5)\n",
    "\n",
    "t1 = time.time()\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "linesH = cv2.HoughLinesP(edges, rho=1, theta=np.pi/360, threshold=50, minLineLength=50, maxLineGap=10)\n",
    "t2 = time.time()\n",
    "\n",
    "linesL = lsd(gray)\n",
    "t3 = time.time()\n",
    "\n",
    "img2 = img00.copy()\n",
    "for line in linesH:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "\n",
    "    # 赤線を引く\n",
    "    img2 = cv2.line(img2, (x1,y1), (x2,y2), (0,0,255), 3)\n",
    "\n",
    "cv2.imwrite('samp_hagh.jpg',img2)\n",
    "img3 = img00.copy()\n",
    "img4 = img00.copy()\n",
    "for line in linesL:\n",
    "    x1, y1, x2, y2 = map(int,line[:4])\n",
    "    img3 = cv2.line(img3, (x1,y1), (x2,y2), (0,0,255), 3)\n",
    "    if (x2-x1)**2 + (y2-y1)**2 > 1000:\n",
    "       # 赤線を引く\n",
    "       img4 = cv2.line(img4, (x1,y1), (x2,y2), (0,0,255), 3)\n",
    "print(\"Hagh\")\n",
    "print(len(linesH),\"lines\")\n",
    "print(t2-t1,\"sec\")\n",
    "print(\"time per a line :{:.4f}\".format((t2-t1)/len(linesH)))\n",
    "print(\"LSD\")\n",
    "print(len(linesL),\"lines\")\n",
    "print(t3-t2,\"sec\")\n",
    "print(\"time per a line {:.4f}\".format((t3-t2)/len(linesL)))\n",
    "cv2.imwrite('samp_pylsd.jpg',img3)\n",
    "cv2.imwrite('samp_pylsd2.jpg',img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像をグレースケールで読み込む\n",
    "imgcol = cv2.imread(\"./res/ATRMoji00.png\",1)\n",
    "img = cv2.imread(\"./res/ATRMoji00.png\",0)\n",
    "temp = cv2.imread(\"./res/ATRMoji01.png\", 0)\n",
    "\n",
    "#マッチングテンプレートを実行\n",
    "result = cv2.matchTemplate(img, temp, cv2.TM_CCOEFF_NORMED)\n",
    "print(result)\n",
    "#類似度の設定(0~1)\n",
    "threshold = 0.8\n",
    "#検出結果から検出領域の位置を取得\n",
    "loc = np.where(result >= threshold)\n",
    "#検出領域を四角で囲んで保存\n",
    "result = cv2.imread(\"./res/ATRMoji00.png\")\n",
    "w, h = temp.shape[::-1]\n",
    "for top_left in zip(*loc[::-1]):\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(result,top_left, bottom_right, (255, 0, 0), 2)\n",
    "    np.append(a_2d, a_2d_ex, axis=1)\n",
    "display_cv_image(result, '.png')\n",
    "cv2.imwrite(\"result2.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrin(x1,y1,x2,y2,array):\n",
    "    for row in array:\n",
    "        if x1>row[0] and y1>row[1]:\n",
    "            print(x1)\n",
    "            print(y1)\n",
    "            return 0\n",
    "        if x2<row[2] and y2<row[3]:\n",
    "            print(x2)\n",
    "            print(y2)\n",
    "            return 0\n",
    "    print (array)\n",
    "    return 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrin(x1,y1,x2,y2,array):\n",
    "    for row in array:\n",
    "        if x1>row[0] and y1>row[1] and x1<row[2] and y1<row[3]:\n",
    "            return 0\n",
    "        if x2>row[0] and y2>row[1] and x2<row[2] and y2<row[3]:\n",
    "            return 0\n",
    "    #print (array)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrin(x1,y1,x2,y2,array):\n",
    "    a = 10\n",
    "    for row in array:\n",
    "        if x1>=row[0]-a and y1>=row[1]-a and x1<=row[2]+a and y1<=row[3]+a:\n",
    "            if x2>=row[0]-a and y2>=row[1]-a and x2<=row[2]+a and y2<=row[3]+a:\n",
    "                return 0\n",
    "    #print (array)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[2,2,4,4]])\n",
    "#画像をグレースケールで読み込む\n",
    "imgcol = cv2.imread(\"./res/ATRMoji00.png\",1)\n",
    "img = cv2.imread(\"./res/ATRMoji00.png\",0)\n",
    "temp = cv2.imread(\"./res/ATRMoji01.png\", 0)\n",
    "\n",
    "#マッチングテンプレートを実行\n",
    "result = cv2.matchTemplate(img, temp, cv2.TM_CCOEFF_NORMED)\n",
    "print(result)\n",
    "#類似度の設定(0~1)\n",
    "threshold = 0.8\n",
    "#検出結果から検出領域の位置を取得\n",
    "loc = np.where(result >= threshold)\n",
    "#検出領域を四角で囲んで保存\n",
    "result = cv2.imread(\"./res/ATRMoji00.png\")\n",
    "w, h = temp.shape[::-1]\n",
    "for top_left in zip(*loc[::-1]):\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(result,top_left, bottom_right, (255, 0, 0), 2)\n",
    "    print([top_left[0],top_left[1],top_left[0] + w, top_left[1] + h])\n",
    "    arr = np.append(arr, [[top_left[0],top_left[1],top_left[0] + w, top_left[1] + h]], axis=0)\n",
    "display_cv_image(result, '.png')\n",
    "print (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img00 = imgcol.copy()\n",
    "#img00 = cv2.resize(img00,(int(img00.shape[1]/5),int(img00.shape[0]/5)))\n",
    "gray = cv2.cvtColor(img00,cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray,(5,5),5)\n",
    "\n",
    "t1 = time.time()\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "linesH = cv2.HoughLinesP(edges, rho=1, theta=np.pi/360, threshold=50, minLineLength=50, maxLineGap=10)\n",
    "t2 = time.time()\n",
    "\n",
    "linesL = lsd(gray)\n",
    "t3 = time.time()\n",
    "\n",
    "img2 = img00.copy()\n",
    "for line in linesL:\n",
    "    x1, y1, x2, y2 =  map(int,line[:4])\n",
    "    if arrin(x1, y1, x2, y2,arr):\n",
    "        # 赤線を引く\n",
    "        #print(str(x1)+\":\"+str(y1)+\":\"+str(x2)+\":\"+str(y2))\n",
    "        img2 = cv2.line(img2, (x1,y1), (x2,y2), (0,0,255), 3)\n",
    "    else :\n",
    "        #print(str(x1)+\":\"+str(y1)+\":\"+str(x2)+\":\"+str(y2))\n",
    "        img2 = cv2.line(img2, (x1,y1), (x2,y2), (0,255,0), 3)\n",
    "\n",
    "cv2.imwrite('samp_haghJOUKEN-9.jpg',img2)\n",
    "img3 = img00.copy()\n",
    "img4 = img00.copy()\n",
    "for line in linesL:\n",
    "    x1, y1, x2, y2 = map(int,line[:4])\n",
    "    img3 = cv2.line(img3, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "    if (x2-x1)**2 + (y2-y1)**2 > 1000:\n",
    "        if arrin(x1, y1, x2, y2,arr):\n",
    "            # 赤線を引く\n",
    "            #print(str(x1)+\":\"+str(y1)+\":\"+str(x2)+\":\"+str(y2))\n",
    "            img4 = cv2.line(img2, (x1,y1), (x2,y2), (0,0,255), 3)\n",
    "        else :\n",
    "            #print(str(x1)+\":\"+str(y1)+\":\"+str(x2)+\":\"+str(y2))\n",
    "            img4 = cv2.line(img2, (x1,y1), (x2,y2), (0,255,0), 3)\n",
    "print(\"Hagh\")\n",
    "print(len(linesH),\"lines\")\n",
    "print(t2-t1,\"sec\")\n",
    "print(\"time per a line :{:.4f}\".format((t2-t1)/len(linesH)))\n",
    "print(\"LSD\")\n",
    "print(len(linesL),\"lines\")\n",
    "print(t3-t2,\"sec\")\n",
    "print(\"time per a line {:.4f}\".format((t3-t2)/len(linesL)))\n",
    "\n",
    "cv2.imwrite(time_file_name(\"lsd2-2.jpg\"),img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
